{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lalonde DR Analysis Workflow with Veldra\n",
        "\n",
        "This notebook demonstrates scenario-driven causal analysis using the Lalonde training program data.\n",
        "Goal: estimate treatment effect on 1978 earnings (`re78`) with **ATT** as the default estimand.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "- This notebook fetches Lalonde data from a public URL on first run.\n",
        "- The normalized data is cached locally and reused on subsequent runs.\n",
        "- DR estimation is run through `veldra.api.estimate_dr` (no direct core call).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "from veldra.api import estimate_dr\n",
        "\n",
        "\n",
        "def _resolve_repo_root(start: Path) -> Path:\n",
        "    current = start.resolve()\n",
        "    candidates = [current, *current.parents]\n",
        "    for base in candidates:\n",
        "        if (base / \"pyproject.toml\").exists() and (base / \"examples\").exists():\n",
        "            return base\n",
        "    return start.resolve()\n",
        "\n",
        "\n",
        "ROOT = _resolve_repo_root(Path.cwd())\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "OUT_DIR = ROOT / \"examples\" / \"out\" / \"notebook_lalonde_dr\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CACHE_PATH = OUT_DIR / \"lalonde_raw.parquet\"\n",
        "SUMMARY_PATH = OUT_DIR / \"lalonde_analysis_summary.json\"\n",
        "\n",
        "LALONDE_URL = \"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/MatchIt/lalonde.csv\"\n",
        "TARGET_COL = \"re78\"\n",
        "TREATMENT_COL = \"treat\"\n",
        "\n",
        "REQUIRED_COLUMNS = [\n",
        "    \"treat\",\n",
        "    \"re78\",\n",
        "    \"age\",\n",
        "    \"educ\",\n",
        "    \"black\",\n",
        "    \"hispan\",\n",
        "    \"married\",\n",
        "    \"nodegree\",\n",
        "    \"re74\",\n",
        "    \"re75\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _normalize_lalonde(raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    frame = raw.copy()\n",
        "    if \"race\" in frame.columns:\n",
        "        race = frame[\"race\"].astype(str).str.lower()\n",
        "        frame[\"black\"] = (race == \"black\").astype(int)\n",
        "        frame[\"hispan\"] = (race == \"hispan\").astype(int)\n",
        "    for col in [\"treat\", \"married\", \"nodegree\", \"age\", \"educ\", \"re74\", \"re75\", \"re78\"]:\n",
        "        frame[col] = pd.to_numeric(frame[col], errors=\"coerce\")\n",
        "    frame = frame.dropna(subset=[\"treat\", \"re78\", \"age\", \"educ\", \"married\", \"nodegree\", \"re74\", \"re75\"])\n",
        "    frame[\"treat\"] = frame[\"treat\"].astype(int)\n",
        "    frame[\"married\"] = frame[\"married\"].astype(int)\n",
        "    frame[\"nodegree\"] = frame[\"nodegree\"].astype(int)\n",
        "    frame[\"black\"] = frame[\"black\"].fillna(0).astype(int)\n",
        "    frame[\"hispan\"] = frame[\"hispan\"].fillna(0).astype(int)\n",
        "\n",
        "    normalized = frame[REQUIRED_COLUMNS].copy()\n",
        "    return normalized.reset_index(drop=True)\n",
        "\n",
        "\n",
        "if CACHE_PATH.exists():\n",
        "    lalonde_df = pd.read_parquet(CACHE_PATH)\n",
        "    cache_mode = \"cache\"\n",
        "else:\n",
        "    raw_df = pd.read_csv(LALONDE_URL)\n",
        "    lalonde_df = _normalize_lalonde(raw_df)\n",
        "    lalonde_df.to_parquet(CACHE_PATH, index=False)\n",
        "    cache_mode = \"url\"\n",
        "\n",
        "print(f\"cache_mode={cache_mode}\")\n",
        "print(f\"cache_path={CACHE_PATH}\")\n",
        "display(lalonde_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing = [col for col in REQUIRED_COLUMNS if col not in lalonde_df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "print(\"n_rows:\", len(lalonde_df))\n",
        "print(\"treated:\", int(lalonde_df[TREATMENT_COL].sum()))\n",
        "print(\"control:\", int((lalonde_df[TREATMENT_COL] == 0).sum()))\n",
        "\n",
        "group_summary = lalonde_df.groupby(TREATMENT_COL)[[\"age\", \"educ\", \"re74\", \"re75\", \"re78\"]].agg([\"mean\", \"std\"])\n",
        "display(group_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"config_version\": 1,\n",
        "    \"task\": {\"type\": \"regression\"},\n",
        "    \"data\": {\n",
        "        \"path\": str(CACHE_PATH),\n",
        "        \"target\": TARGET_COL,\n",
        "        \"id_cols\": [],\n",
        "        \"drop_cols\": [],\n",
        "    },\n",
        "    \"split\": {\"type\": \"kfold\", \"n_splits\": 5, \"seed\": 42},\n",
        "    \"train\": {\"seed\": 42},\n",
        "    \"causal\": {\n",
        "        \"method\": \"dr\",\n",
        "        \"treatment_col\": TREATMENT_COL,\n",
        "        \"estimand\": \"att\",  # explicit default\n",
        "        \"propensity_calibration\": \"platt\",  # explicit default\n",
        "        \"propensity_clip\": 0.01,\n",
        "        \"cross_fit\": True,\n",
        "    },\n",
        "    \"export\": {\"artifact_dir\": \"artifacts\"},\n",
        "}\n",
        "\n",
        "result = estimate_dr(config)\n",
        "print(\"run_id:\", result.run_id)\n",
        "print(\"estimate:\", result.estimate)\n",
        "print(\"95% CI:\", result.ci_lower, result.ci_upper)\n",
        "display(pd.DataFrame([result.metrics]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_path = Path(result.metadata[\"summary_path\"])\n",
        "obs_path = Path(result.metadata[\"observation_path\"])\n",
        "\n",
        "summary = json.loads(summary_path.read_text(encoding=\"utf-8\"))\n",
        "obs = pd.read_parquet(obs_path)\n",
        "\n",
        "estimate_table = pd.DataFrame(\n",
        "    [\n",
        "        {\"metric\": \"naive\", \"value\": result.metrics.get(\"naive\")},\n",
        "        {\"metric\": \"ipw\", \"value\": result.metrics.get(\"ipw\")},\n",
        "        {\"metric\": \"dr\", \"value\": result.metrics.get(\"dr\")},\n",
        "        {\"metric\": \"ci_lower\", \"value\": result.ci_lower},\n",
        "        {\"metric\": \"ci_upper\", \"value\": result.ci_upper},\n",
        "    ]\n",
        ")\n",
        "\n",
        "display(estimate_table)\n",
        "display(obs.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_df = estimate_table[estimate_table[\"metric\"].isin([\"naive\", \"ipw\", \"dr\"])].copy()\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.bar(plot_df[\"metric\"], plot_df[\"value\"], color=[\"#9ca3af\", \"#60a5fa\", \"#10b981\"])\n",
        "ax.errorbar(\n",
        "    x=[2],\n",
        "    y=[result.estimate],\n",
        "    yerr=[[result.estimate - result.ci_lower], [result.ci_upper - result.estimate]],\n",
        "    fmt=\"o\",\n",
        "    color=\"black\",\n",
        "    capsize=5,\n",
        ")\n",
        "ax.set_title(\"Naive vs IPW vs DR (ATT)\")\n",
        "ax.set_ylabel(\"Estimated effect on re78\")\n",
        "ax.grid(axis=\"y\", alpha=0.2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
        "for idx, col in enumerate([\"e_raw\", \"e_hat\"]):\n",
        "    axes[idx].hist(obs.loc[obs[\"treatment\"] == 1, col], bins=30, alpha=0.6, label=\"treated\")\n",
        "    axes[idx].hist(obs.loc[obs[\"treatment\"] == 0, col], bins=30, alpha=0.6, label=\"control\")\n",
        "    axes[idx].set_title(f\"{col} distribution\")\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].grid(alpha=0.2)\n",
        "axes[0].set_ylabel(\"count\")\n",
        "axes[1].legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _weighted_mean(x: np.ndarray, w: np.ndarray) -> float:\n",
        "    denom = float(np.sum(w))\n",
        "    if denom <= 0:\n",
        "        return float(np.nan)\n",
        "    return float(np.sum(x * w) / denom)\n",
        "\n",
        "\n",
        "def _weighted_var(x: np.ndarray, w: np.ndarray) -> float:\n",
        "    mu = _weighted_mean(x, w)\n",
        "    if np.isnan(mu):\n",
        "        return float(np.nan)\n",
        "    denom = float(np.sum(w))\n",
        "    if denom <= 0:\n",
        "        return float(np.nan)\n",
        "    return float(np.sum(w * (x - mu) ** 2) / denom)\n",
        "\n",
        "\n",
        "def _smd(x_t: np.ndarray, x_c: np.ndarray) -> float:\n",
        "    var_t = np.var(x_t)\n",
        "    var_c = np.var(x_c)\n",
        "    denom = np.sqrt((var_t + var_c) / 2.0)\n",
        "    return float((np.mean(x_t) - np.mean(x_c)) / denom) if denom > 0 else 0.0\n",
        "\n",
        "\n",
        "def _smd_weighted(x_t: np.ndarray, w_t: np.ndarray, x_c: np.ndarray, w_c: np.ndarray) -> float:\n",
        "    mu_t = _weighted_mean(x_t, w_t)\n",
        "    mu_c = _weighted_mean(x_c, w_c)\n",
        "    var_t = _weighted_var(x_t, w_t)\n",
        "    var_c = _weighted_var(x_c, w_c)\n",
        "    denom = np.sqrt((var_t + var_c) / 2.0)\n",
        "    if denom <= 0 or np.isnan(denom):\n",
        "        return 0.0\n",
        "    return float((mu_t - mu_c) / denom)\n",
        "\n",
        "\n",
        "balance_cols = [\"age\", \"educ\", \"black\", \"hispan\", \"married\", \"nodegree\", \"re74\", \"re75\"]\n",
        "analysis_df = lalonde_df.copy()\n",
        "analysis_df[\"w_att\"] = obs[\"weight\"].to_numpy(dtype=float)\n",
        "\n",
        "records = []\n",
        "for col in balance_cols:\n",
        "    t_mask = analysis_df[TREATMENT_COL] == 1\n",
        "    c_mask = analysis_df[TREATMENT_COL] == 0\n",
        "    x_t = analysis_df.loc[t_mask, col].to_numpy(dtype=float)\n",
        "    x_c = analysis_df.loc[c_mask, col].to_numpy(dtype=float)\n",
        "    w_t = analysis_df.loc[t_mask, \"w_att\"].to_numpy(dtype=float)\n",
        "    w_c = analysis_df.loc[c_mask, \"w_att\"].to_numpy(dtype=float)\n",
        "\n",
        "    records.append(\n",
        "        {\n",
        "            \"feature\": col,\n",
        "            \"smd_unweighted\": _smd(x_t, x_c),\n",
        "            \"smd_weighted\": _smd_weighted(x_t, w_t, x_c, w_c),\n",
        "        }\n",
        "    )\n",
        "\n",
        "balance_df = pd.DataFrame(records).sort_values(\"smd_unweighted\", key=lambda s: np.abs(s), ascending=False)\n",
        "display(balance_df)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "y = np.arange(len(balance_df))\n",
        "ax.scatter(balance_df[\"smd_unweighted\"], y, label=\"unweighted\", color=\"#ef4444\")\n",
        "ax.scatter(balance_df[\"smd_weighted\"], y, label=\"weighted (ATT)\", color=\"#2563eb\")\n",
        "ax.axvline(0.0, color=\"black\", linewidth=1)\n",
        "ax.axvline(0.1, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
        "ax.axvline(-0.1, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
        "ax.set_yticks(y)\n",
        "ax.set_yticklabels(balance_df[\"feature\"])\n",
        "ax.set_xlabel(\"Standardized Mean Difference\")\n",
        "ax.set_title(\"Covariate balance: before vs after ATT weighting\")\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analysis_summary = {\n",
        "    \"run_id\": result.run_id,\n",
        "    \"estimand\": result.estimand,\n",
        "    \"estimate\": result.estimate,\n",
        "    \"ci_lower\": result.ci_lower,\n",
        "    \"ci_upper\": result.ci_upper,\n",
        "    \"metrics\": result.metrics,\n",
        "    \"summary_path\": result.metadata.get(\"summary_path\"),\n",
        "    \"observation_path\": result.metadata.get(\"observation_path\"),\n",
        "    \"cache_path\": str(CACHE_PATH),\n",
        "}\n",
        "\n",
        "SUMMARY_PATH.write_text(json.dumps(analysis_summary, indent=2, sort_keys=True), encoding=\"utf-8\")\n",
        "print(\"analysis_summary_path=\", SUMMARY_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation Notes\n",
        "\n",
        "- `naive` vs `ipw` vs `dr` helps inspect confounding adjustment impact.\n",
        "- If weighted SMD is still large for multiple covariates, overlap/model misspecification risk remains.\n",
        "- For production use, combine this with sensitivity checks and cohort diagnostics.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}