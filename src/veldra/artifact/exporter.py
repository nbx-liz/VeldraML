"""Artifact export helpers."""

from __future__ import annotations

import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from veldra.api.artifact import Artifact
from veldra.api.exceptions import VeldraValidationError
from veldra.config.io import save_run_config

_RUNTIME_PREDICT_PY = """\
from __future__ import annotations

from pathlib import Path
from typing import Any

import lightgbm as lgb
import pandas as pd


def load_booster(export_dir: str | Path) -> lgb.Booster:
    base = Path(export_dir)
    model_path = base / "model.lgb.txt"
    if not model_path.exists():
        raise FileNotFoundError(f"model file not found: {model_path}")
    return lgb.Booster(model_file=str(model_path))


def predict_frame(export_dir: str | Path, frame: pd.DataFrame) -> Any:
    booster = load_booster(export_dir)
    return booster.predict(frame)
"""

_PYTHON_EXPORT_README = """\
# Veldra Export Package (Python)

This export is generated by `veldra.api.runner.export(..., format="python")`.

## Contents
- `model.lgb.txt`
- `manifest.json`
- `run_config.yaml`
- `feature_schema.json`
- `metadata.json`
- `runtime_predict.py`

## Usage
```python
import pandas as pd
from runtime_predict import predict_frame

frame = pd.read_csv("input.csv")
pred = predict_frame(".", frame)
print(pred[:5])
```
"""


def _metadata_payload(artifact: Artifact, *, export_format: str) -> dict[str, Any]:
    payload: dict[str, Any] = {
        "run_id": artifact.manifest.run_id,
        "task_type": artifact.run_config.task.type,
        "export_format": export_format,
        "created_at_utc": datetime.now(timezone.utc).isoformat(),
        "project_version": artifact.manifest.project_version,
        "manifest_version": artifact.manifest.manifest_version,
        "config_version": artifact.run_config.config_version,
    }
    if artifact.run_config.task.type == "frontier":
        payload["frontier_alpha"] = float(
            artifact.feature_schema.get("frontier_alpha", artifact.run_config.frontier.alpha)
        )
    return payload


def export_python_package(artifact: Artifact, out_dir: str | Path) -> Path:
    """Export artifact into a lightweight Python inference package."""
    if artifact.model_text is None:
        raise VeldraValidationError("Artifact model is missing and cannot be exported.")
    if not artifact.feature_schema:
        raise VeldraValidationError("Artifact feature_schema is missing and cannot be exported.")

    target = Path(out_dir)
    target.mkdir(parents=True, exist_ok=True)
    (target / "manifest.json").write_text(
        artifact.manifest.model_dump_json(indent=2),
        encoding="utf-8",
    )
    save_run_config(artifact.run_config, target / "run_config.yaml")
    (target / "feature_schema.json").write_text(
        json.dumps(artifact.feature_schema, indent=2, sort_keys=True),
        encoding="utf-8",
    )
    (target / "model.lgb.txt").write_text(artifact.model_text, encoding="utf-8")
    (target / "metadata.json").write_text(
        json.dumps(_metadata_payload(artifact, export_format="python"), indent=2, sort_keys=True),
        encoding="utf-8",
    )
    (target / "runtime_predict.py").write_text(_RUNTIME_PREDICT_PY, encoding="utf-8")
    (target / "README.md").write_text(_PYTHON_EXPORT_README, encoding="utf-8")
    return target


def _load_onnx_toolchain() -> tuple[Any, Any]:
    try:
        import onnxmltools
        from onnxconverter_common.data_types import FloatTensorType
    except ModuleNotFoundError as exc:
        missing = getattr(exc, "name", "onnx toolchain package")
        raise VeldraValidationError(
            "ONNX export requires optional dependencies. "
            f"Missing package: '{missing}'. "
            "Install with: uv sync --extra export-onnx"
        ) from exc
    return onnxmltools, FloatTensorType


def export_onnx_model(artifact: Artifact, out_dir: str | Path) -> Path:
    """Export artifact model into ONNX format when optional deps are available."""
    if artifact.model_text is None:
        raise VeldraValidationError("Artifact model is missing and cannot be exported.")

    feature_names = artifact.feature_schema.get("feature_names")
    if not isinstance(feature_names, list) or not feature_names:
        raise VeldraValidationError(
            "feature_schema.feature_names is missing and cannot export ONNX."
        )

    onnxmltools, float_tensor_type = _load_onnx_toolchain()
    target = Path(out_dir)
    target.mkdir(parents=True, exist_ok=True)

    booster = artifact._get_booster()
    initial_types = [("input", float_tensor_type([None, len(feature_names)]))]
    try:
        onnx_model = onnxmltools.convert_lightgbm(booster, initial_types=initial_types)
    except Exception as exc:
        raise VeldraValidationError(
            "ONNX conversion failed"
            f" for task.type='{artifact.run_config.task.type}'. "
            "Check converter compatibility for the current LightGBM model and "
            "ensure optional dependencies are installed with: uv sync --extra export-onnx"
        ) from exc
    model_path = target / "model.onnx"
    try:
        with model_path.open("wb") as fp:
            fp.write(onnx_model.SerializeToString())
    except Exception as exc:
        raise VeldraValidationError(
            "Failed to serialize/write ONNX model artifact. "
            "Verify converter output compatibility and filesystem permissions."
        ) from exc

    (target / "metadata.json").write_text(
        json.dumps(_metadata_payload(artifact, export_format="onnx"), indent=2, sort_keys=True),
        encoding="utf-8",
    )
    return target
